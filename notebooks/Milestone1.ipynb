{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1\n",
    "\n",
    "In this milestone, we are using the Figshare API to pull data and analyze it in upcoming milestones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data from Figshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily rainfall over NSW, Australia\n",
    "# https://figshare.com/articles/dataset/Daily_rainfall_over_NSW_Australia/14096681\n",
    "article_id = 14096681\n",
    "# Metadata for the download\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 26579150,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'size': 58863,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e'},\n",
       " {'id': 26579171,\n",
       "  'name': 'environment.yml',\n",
       "  'size': 192,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34'},\n",
       " {'id': 26586554,\n",
       "  'name': 'README.md',\n",
       "  'size': 5422,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c'},\n",
       " {'id': 26766812,\n",
       "  'name': 'data.zip',\n",
       "  'size': 814041183,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9'},\n",
       " {'id': 26766815,\n",
       "  'name': 'get_data.py',\n",
       "  'size': 4113,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List files in the associated dataset\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)\n",
    "files = data[\"files\"]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve `data.zip`\n",
    "files_to_dl = [\"data.zip\"]\n",
    "for f in files:\n",
    "    if f[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(f[\"download_url\"], f\"{output_directory}/{f['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract `data.zip`\n",
    "output_zip_file = os.path.join(output_directory, \"./data.zip\")\n",
    "with zipfile.ZipFile(output_zip_file, 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/MPI-ESM-1-2-HAM_daily_rainfall_NSW.csv',\n",
       " '../data/AWI-ESM-1-1-LR_daily_rainfall_NSW.csv',\n",
       " '../data/NorESM2-LM_daily_rainfall_NSW.csv',\n",
       " '../data/ACCESS-CM2_daily_rainfall_NSW.csv',\n",
       " '../data/FGOALS-f3-L_daily_rainfall_NSW.csv',\n",
       " '../data/CMCC-CM2-HR4_daily_rainfall_NSW.csv',\n",
       " '../data/MRI-ESM2-0_daily_rainfall_NSW.csv',\n",
       " '../data/GFDL-CM4_daily_rainfall_NSW.csv',\n",
       " '../data/BCC-CSM2-MR_daily_rainfall_NSW.csv',\n",
       " '../data/EC-Earth3-Veg-LR_daily_rainfall_NSW.csv',\n",
       " '../data/CMCC-ESM2_daily_rainfall_NSW.csv',\n",
       " '../data/NESM3_daily_rainfall_NSW.csv',\n",
       " '../data/MPI-ESM1-2-LR_daily_rainfall_NSW.csv',\n",
       " '../data/ACCESS-ESM1-5_daily_rainfall_NSW.csv',\n",
       " '../data/FGOALS-g3_daily_rainfall_NSW.csv',\n",
       " '../data/INM-CM4-8_daily_rainfall_NSW.csv',\n",
       " '../data/MPI-ESM1-2-HR_daily_rainfall_NSW.csv',\n",
       " '../data/TaiESM1_daily_rainfall_NSW.csv',\n",
       " '../data/NorESM2-MM_daily_rainfall_NSW.csv',\n",
       " '../data/CMCC-CM2-SR5_daily_rainfall_NSW.csv',\n",
       " '../data/KIOST-ESM_daily_rainfall_NSW.csv',\n",
       " '../data/INM-CM5-0_daily_rainfall_NSW.csv',\n",
       " '../data/MIROC6_daily_rainfall_NSW.csv',\n",
       " '../data/BCC-ESM1_daily_rainfall_NSW.csv',\n",
       " '../data/GFDL-ESM4_daily_rainfall_NSW.csv',\n",
       " '../data/CanESM5_daily_rainfall_NSW.csv',\n",
       " '../data/SAM0-UNICON_daily_rainfall_NSW.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather a list of files of CSV to merge\n",
    "files = glob.glob(f'{output_directory}/*.csv')\n",
    "files.remove(f'{output_directory}/observed_daily_rainfall_SYD.csv')\n",
    "# files = files[0:1]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_merge = [\"time\", \"lat_min\", \"lat_max\", \"lon_min\", \"lon_max\", \"rain (mm/day)\"]\n",
    "\n",
    "combined_path = f'{output_directory}/combined_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 17s, sys: 12.9 s, total: 3min 30s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# files = glob.glob('dailyrainfall/*.csv')\n",
    "# df = pd.concat((pd.read_csv(files, index_col=0)\n",
    "#                 .assign(model=re.findall(\"/([^_]*)\", file)[0])\n",
    "#                 for file in files)\n",
    "#               )\n",
    "\n",
    "# A Pythonic way (but not the most memory-efficient way) for merging the data\n",
    "df = pd.concat((pd.read_csv(f, index_col=0, usecols=columns_to_merge)\n",
    "                .assign(model=f[len(output_directory)+1:-len(\"_daily_rainfall_NSW.csv\")])\n",
    "                for f in files)\n",
    "              )\n",
    "df.to_csv(combined_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6G\t../data/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh ../data/combined_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62467843, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889-01-01 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.244226e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-02 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.217326e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-03 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.498125e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-04 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.251282e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-05 12:00:00</th>\n",
       "      <td>-35.439867</td>\n",
       "      <td>-33.574619</td>\n",
       "      <td>141.5625</td>\n",
       "      <td>143.4375</td>\n",
       "      <td>4.270161e-13</td>\n",
       "      <td>MPI-ESM-1-2-HAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lat_min    lat_max   lon_min   lon_max  rain (mm/day)  \\\n",
       "time                                                                           \n",
       "1889-01-01 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.244226e-13   \n",
       "1889-01-02 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.217326e-13   \n",
       "1889-01-03 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.498125e-13   \n",
       "1889-01-04 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.251282e-13   \n",
       "1889-01-05 12:00:00 -35.439867 -33.574619  141.5625  143.4375   4.270161e-13   \n",
       "\n",
       "                               model  \n",
       "time                                  \n",
       "1889-01-01 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-02 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-03 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-04 12:00:00  MPI-ESM-1-2-HAM  \n",
       "1889-01-05 12:00:00  MPI-ESM-1-2-HAM  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> | Team Member  | Operating System | RAM  | Processor         | Is SSD | Time taken  |\n",
    "> |:------------:|:----------------:|:----:|:-----------------:|:------:|:-----------:|\n",
    "> | Chen, Ziyi   |  OSX 13.2.1      | 32GB | M1 (10 processors)| YES    |  3min 30s   |\n",
    "> | Guron, Mike  |                  |      |                   |        |             |\n",
    "> | Raina, Roan  |                  |      |                   |        |             |\n",
    "> | Wong, Kelvin | Linux Mint 21    | 16GB | AMD Ryzen 5 3500U | YES    | 10min 6secs |\n",
    "> \n",
    "> Table 1: Time taken to combine the CSV files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "This is the baseline time needed to load the CSV file as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.2 s, sys: 4.48 s, total: 32.7 s\n",
      "Wall time: 34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(f\"{output_directory}/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62467843 entries, 0 to 62467842\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   time           object \n",
      " 1   lat_min        float64\n",
      " 2   lat_max        float64\n",
      " 3   lon_min        float64\n",
      " 4   lon_max        float64\n",
      " 5   rain (mm/day)  float64\n",
      " 6   model          object \n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 3.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> | Team Member  | Operating System | RAM  | Processor         | Is SSD | Time taken    | Memory usage |\n",
    "> |:------------:|:----------------:|:----:|:-----------------:|:------:|:-------------:|:------------:|\n",
    "> | Chen, Ziyi   |  OSX 13.2.1      | 32GB | M1 (10 processors)| YES    |  34 secs      |  3.3+ GB     |\n",
    "> | Guron, Mike  |                  |      |                   |        |               |              |\n",
    "> | Raina, Roan  |                  |      |                   |        |               |              |\n",
    "> | Wong, Kelvin | Linux Mint 21    | 16GB | AMD Ryzen 5 3500U | YES    | 2 min 45 secs | 3.3+ GB      |\n",
    "> \n",
    "> Table 2: Time taken to read the combined CSV (baseline)\n",
    "\n",
    "#### Observations from Baseline\n",
    "\n",
    "(WIP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Change the `dtype` of the data\n",
    "\n",
    "We notice that by default it uses `float64` if we do not specify it. First, we try to see if switching to `float32` would make a smaller memory footprint, as well as a faster time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.1 s, sys: 3.04 s, total: 31.1 s\n",
      "Wall time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_float32 = pd.read_csv(f\"{output_directory}/combined_data.csv\", dtype={\n",
    "    'lat_min': 'float32',\n",
    "    'lat_max': 'float32',\n",
    "    'lon_min': 'float32',\n",
    "    'lon_max': 'float32',\n",
    "    'rain (mm/day)': 'float32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62467843 entries, 0 to 62467842\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   time           object \n",
      " 1   lat_min        float32\n",
      " 2   lat_max        float32\n",
      " 3   lon_min        float32\n",
      " 4   lon_max        float32\n",
      " 5   rain (mm/day)  float32\n",
      " 6   model          object \n",
      "dtypes: float32(5), object(2)\n",
      "memory usage: 2.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df_float32.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> | Team Member  | Operating System | RAM  | Processor         | Is SSD | Time taken    | Memory usage |\n",
    "> |:------------:|:----------------:|:----:|:-----------------:|:------:|:-------------:|:------------:|\n",
    "> | Chen, Ziyi   |  OSX 13.2.1      | 32GB | M1 (10 processors)| YES    | 31.7 secs     | 2.1+ GB      |\n",
    "> | Guron, Mike  |                  |      |                   |        |               |              |\n",
    "> | Raina, Roan  |                  |      |                   |        |               |              |\n",
    "> | Wong, Kelvin | Linux Mint 21    | 16GB | AMD Ryzen 5 3500U | YES    | 2 min 28 secs | 2.1+ GB      |\n",
    "> \n",
    "> Table 3: Time taken to read the combined CSV (approach 1: use `float32` instead of `float64`)\n",
    "\n",
    "#### Observations from Approach 1\n",
    "\n",
    "(WIP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Load only column(s) we want\n",
    "\n",
    "The dataset contains a number of columns that we may not need to use in one go. In this approach, we try to just load one column from the combined CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 s, sys: 1 s, total: 16 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_only_rain = pd.read_csv(f\"{output_directory}/combined_data.csv\", usecols=[\"rain (mm/day)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62467843 entries, 0 to 62467842\n",
      "Data columns (total 1 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   rain (mm/day)  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 476.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_only_rain.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> | Team Member  | Operating System | RAM  | Processor         | Is SSD | Time taken    | Memory usage |\n",
    "> |:------------:|:----------------:|:----:|:-----------------:|:------:|:-------------:|:------------:|\n",
    "> | Chen, Ziyi   | OSX 13.2.1       | 32GB | M1 (10 processors)| YES    |   16.1 s      | 476.6 MB     |\n",
    "> | Guron, Mike  |                  |      |                   |        |               |              |\n",
    "> | Raina, Roan  |                  |      |                   |        |               |              |\n",
    "> | Wong, Kelvin | Linux Mint 21    | 16GB | AMD Ryzen 5 3500U | YES    | 1 min 6 secs  | 476.6 MB     |\n",
    "> \n",
    "> Table 4: Time taken to read the combined CSV (approach 2: just load `rain (mm/day)`)\n",
    "\n",
    "#### Observations from Approach 2\n",
    "\n",
    "(WIP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA in R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we explore the EDA in R instead of Python. We try \"exporting\" our data frame as a Parquet file for processing in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 s, sys: 2.99 s, total: 13.2 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_parquet(f\"{output_directory}/combined_data.parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Why we choose Parquet?\n",
    "> \n",
    "> (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘arrow’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:utils’:\n",
      "\n",
      "    timestamp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(dplyr)\n",
    "library(arrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "r_parquet <- open_dataset(\"../data/combined_data.parquet\")\n",
    "r_df <- r_parquet |> collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tibble [62,467,843 × 7] (S3: tbl_df/tbl/data.frame)\n",
      " $ time         : chr [1:62467843] \"1889-01-01 12:00:00\" \"1889-01-02 12:00:00\" \"1889-01-03 12:00:00\" \"1889-01-04 12:00:00\" ...\n",
      " $ lat_min      : num [1:62467843] -35.4 -35.4 -35.4 -35.4 -35.4 ...\n",
      " $ lat_max      : num [1:62467843] -33.6 -33.6 -33.6 -33.6 -33.6 ...\n",
      " $ lon_min      : num [1:62467843] 142 142 142 142 142 ...\n",
      " $ lon_max      : num [1:62467843] 143 143 143 143 143 ...\n",
      " $ rain (mm/day): num [1:62467843] 4.24e-13 4.22e-13 4.50e-13 4.25e-13 4.27e-13 ...\n",
      " $ model        : chr [1:62467843] \"MPI-ESM-1-2-HAM\" \"MPI-ESM-1-2-HAM\" \"MPI-ESM-1-2-HAM\" \"MPI-ESM-1-2-HAM\" ...\n",
      "CPU times: user 4.86 s, sys: 268 ms, total: 5.12 s\n",
      "Wall time: 5.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "r_df |> str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "r_df |> summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 6 × 7\n",
      "  time                lat_min lat_max lon_min lon_max `rain (mm/day)` model     \n",
      "  <chr>                 <dbl>   <dbl>   <dbl>   <dbl>           <dbl> <chr>     \n",
      "1 1889-01-01 12:00:00   -35.4   -33.6    142.    143.        4.24e-13 MPI-ESM-1…\n",
      "2 1889-01-02 12:00:00   -35.4   -33.6    142.    143.        4.22e-13 MPI-ESM-1…\n",
      "3 1889-01-03 12:00:00   -35.4   -33.6    142.    143.        4.50e-13 MPI-ESM-1…\n",
      "4 1889-01-04 12:00:00   -35.4   -33.6    142.    143.        4.25e-13 MPI-ESM-1…\n",
      "5 1889-01-05 12:00:00   -35.4   -33.6    142.    143.        4.27e-13 MPI-ESM-1…\n",
      "6 1889-01-06 12:00:00   -35.4   -33.6    142.    143.        4.20e-13 MPI-ESM-1…\n",
      "CPU times: user 93.7 ms, sys: 6.88 ms, total: 101 ms\n",
      "Wall time: 101 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "r_df |> head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# A tibble: 6 × 7\n",
      "  time                lat_min lat_max lon_min lon_max `rain (mm/day)` model     \n",
      "  <chr>                 <dbl>   <dbl>   <dbl>   <dbl>           <dbl> <chr>     \n",
      "1 2014-12-26 12:00:00   -31.7   -29.8    153.    155.        4.91e- 1 MPI-ESM-1…\n",
      "2 2014-12-27 12:00:00   -31.7   -29.8    153.    155.        3.22e- 4 MPI-ESM-1…\n",
      "3 2014-12-28 12:00:00   -31.7   -29.8    153.    155.        4.61e-13 MPI-ESM-1…\n",
      "4 2014-12-29 12:00:00   -31.7   -29.8    153.    155.        5.69e+ 0 MPI-ESM-1…\n",
      "5 2014-12-30 12:00:00   -31.7   -29.8    153.    155.        1.23e+ 1 MPI-ESM-1…\n",
      "6 2014-12-31 12:00:00   -31.7   -29.8    153.    155.        6.33e+ 0 MPI-ESM-1…\n",
      "CPU times: user 18.1 ms, sys: 1.86 ms, total: 19.9 ms\n",
      "Wall time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "r_df |> tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci525",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
