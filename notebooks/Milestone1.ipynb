{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 1\n",
    "\n",
    "In this milestone, we are using the Figshare API to pull data and analyze it in upcoming milestones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data from Figshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.request import urlretrieve\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily rainfall over NSW, Australia\n",
    "# https://figshare.com/articles/dataset/Daily_rainfall_over_NSW_Australia/14096681\n",
    "article_id = 14096681\n",
    "\n",
    "# Metadata for the download\n",
    "url = f\"https://api.figshare.com/v2/articles/{article_id}\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "output_directory = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 26579150,\n",
       "  'name': 'daily_rainfall_2014.png',\n",
       "  'size': 58863,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579150',\n",
       "  'supplied_md5': 'fd32a2ffde300a31f8d63b1825d47e5e',\n",
       "  'computed_md5': 'fd32a2ffde300a31f8d63b1825d47e5e'},\n",
       " {'id': 26579171,\n",
       "  'name': 'environment.yml',\n",
       "  'size': 192,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26579171',\n",
       "  'supplied_md5': '060b2020017eed93a1ee7dd8c65b2f34',\n",
       "  'computed_md5': '060b2020017eed93a1ee7dd8c65b2f34'},\n",
       " {'id': 26586554,\n",
       "  'name': 'README.md',\n",
       "  'size': 5422,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26586554',\n",
       "  'supplied_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c',\n",
       "  'computed_md5': '61858c6cc0e6a6d6663a7e4c75bbd88c'},\n",
       " {'id': 26766812,\n",
       "  'name': 'data.zip',\n",
       "  'size': 814041183,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766812',\n",
       "  'supplied_md5': 'b517383f76e77bd03755a63a8ff83ee9',\n",
       "  'computed_md5': 'b517383f76e77bd03755a63a8ff83ee9'},\n",
       " {'id': 26766815,\n",
       "  'name': 'get_data.py',\n",
       "  'size': 4113,\n",
       "  'is_link_only': False,\n",
       "  'download_url': 'https://ndownloader.figshare.com/files/26766815',\n",
       "  'supplied_md5': '7829028495fd9dec9680ea013474afa6',\n",
       "  'computed_md5': '7829028495fd9dec9680ea013474afa6'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List files in the associated dataset\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "data = json.loads(response.text)\n",
    "files = data[\"files\"]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mif\u001b[39;00m f[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39min\u001b[39;00m files_to_dl:\n\u001b[1;32m      6\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(output_directory, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m     urlretrieve(f[\u001b[39m\"\u001b[39;49m\u001b[39mdownload_url\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00moutput_directory\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mf[\u001b[39m'\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsci525/lib/python3.10/urllib/request.py:270\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    267\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m    269\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m     block \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39;49mread(bs)\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m block:\n\u001b[1;32m    272\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsci525/lib/python3.10/http/client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    463\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 465\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[1;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    467\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/dsci525/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dsci525/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/dsci525/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Retrieve `data.zip`\n",
    "files_to_dl = [\"data.zip\"]\n",
    "\n",
    "for f in files:\n",
    "    if f[\"name\"] in files_to_dl:\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        urlretrieve(f[\"download_url\"], f\"{output_directory}/{f['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract `data.zip`\n",
    "output_zip_file = os.path.join(output_directory, \"/data.zip\")\n",
    "with zipfile.ZipFile(output_zip_file, 'r') as f:\n",
    "    f.extractall(output_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/NorESM2-MM_daily_rainfall_NSW.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather a list of files of CSV to merge\n",
    "files = glob.glob(f'{output_directory}/*.csv')\n",
    "files.remove(f'{output_directory}/observed_daily_rainfall_SYD.csv')\n",
    "files = files[0:1]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_merge = [\"time\", \"lat_min\", \"lat_max\", \"lon_min\", \"lon_max\", \"rain (mm/day)\"]\n",
    "\n",
    "combined_path = f'{output_directory}/combined_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.1 s, sys: 2.37 s, total: 37.5 s\n",
      "Wall time: 37.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# A Pythonic way (but not the most memory-efficient way) for merging the data\n",
    "df = pd.concat((pd.read_csv(f, index_col=0, usecols=columns_to_merge)\n",
    "                .assign(model=f[len(output_directory)+1:-len(\"_daily_rainfall_NSW.csv\")])\n",
    "                for f in files)\n",
    "              )\n",
    "df.to_csv(combined_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.7G\t../data/combined_data.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "du -sh ../data/combined_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62467843, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_min</th>\n",
       "      <th>lat_max</th>\n",
       "      <th>lon_min</th>\n",
       "      <th>lon_max</th>\n",
       "      <th>rain (mm/day)</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1889-01-01 12:00:00</th>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.513492</td>\n",
       "      <td>NorESM2-MM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-02 12:00:00</th>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>NorESM2-MM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-03 12:00:00</th>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>NorESM2-MM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-04 12:00:00</th>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>NorESM2-MM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889-01-05 12:00:00</th>\n",
       "      <td>-35.811518</td>\n",
       "      <td>-34.86911</td>\n",
       "      <td>140.625</td>\n",
       "      <td>141.875</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>NorESM2-MM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lat_min   lat_max  lon_min  lon_max  rain (mm/day)  \\\n",
       "time                                                                        \n",
       "1889-01-01 12:00:00 -35.811518 -34.86911  140.625  141.875       0.513492   \n",
       "1889-01-02 12:00:00 -35.811518 -34.86911  140.625  141.875       0.000923   \n",
       "1889-01-03 12:00:00 -35.811518 -34.86911  140.625  141.875       0.000009   \n",
       "1889-01-04 12:00:00 -35.811518 -34.86911  140.625  141.875       0.000025   \n",
       "1889-01-05 12:00:00 -35.811518 -34.86911  140.625  141.875       0.000013   \n",
       "\n",
       "                          model  \n",
       "time                             \n",
       "1889-01-01 12:00:00  NorESM2-MM  \n",
       "1889-01-02 12:00:00  NorESM2-MM  \n",
       "1889-01-03 12:00:00  NorESM2-MM  \n",
       "1889-01-04 12:00:00  NorESM2-MM  \n",
       "1889-01-05 12:00:00  NorESM2-MM  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> | Team Member  | Operating System | RAM  | Processor         | Is SSD | Time taken  |\n",
    "> |:------------:|:----------------:|:----:|:-----------------:|:------:|:-----------:|\n",
    "> | Chen, Ziyi   |                  |      |                   |        |             |\n",
    "> | Guron, Mike  |                  |      |                   |        |             |\n",
    "> | Raina, Roan  |                  |      |                   |        |             |\n",
    "> | Wong, Kelvin | Linux Mint 21    | 16GB | AMD Ryzen 5 3500U | YES    | 10min 6secs |\n",
    "> \n",
    "> Table 1: Time taken to combine the CSV files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "This is the baseline time needed to load the CSV file as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 3s, sys: 30.3 s, total: 2min 33s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(f\"{output_directory}/combined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62467843 entries, 0 to 62467842\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   time           object \n",
      " 1   lat_min        float64\n",
      " 2   lat_max        float64\n",
      " 3   lon_min        float64\n",
      " 4   lon_max        float64\n",
      " 5   rain (mm/day)  float64\n",
      " 6   model          object \n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 3.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> | Team Member  | Operating System | RAM  | Processor         | Is SSD | Time taken    | Memory usage |\n",
    "> |:------------:|:----------------:|:----:|:-----------------:|:------:|:-------------:|:------------:|\n",
    "> | Chen, Ziyi   |                  |      |                   |        |               |              |\n",
    "> | Guron, Mike  |                  |      |                   |        |               |              |\n",
    "> | Raina, Roan  |                  |      |                   |        |               |              |\n",
    "> | Wong, Kelvin | Linux Mint 21    | 16GB | AMD Ryzen 5 3500U | YES    | 2 min 45 secs | 3.3+ GB      |\n",
    "> \n",
    "> Table 2: Time taken to read the combined CSV (baseline)\n",
    "\n",
    "#### Observations from Baseline\n",
    "\n",
    "(WIP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1: Change the `dtype` of the data\n",
    "\n",
    "We notice that by default it uses `float64` if we do not specify it. First, we try to see if switching to `float32` would make a smaller memory footprint, as well as a faster time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 27.6 s, total: 2min 23s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_float32 = pd.read_csv(f\"{output_directory}/combined_data.csv\", dtype={\n",
    "    'lat_min': 'float32',\n",
    "    'lat_max': 'float32',\n",
    "    'lon_min': 'float32',\n",
    "    'lon_max': 'float32',\n",
    "    'rain (mm/day)': 'float32'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62467843 entries, 0 to 62467842\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   time           object \n",
      " 1   lat_min        float32\n",
      " 2   lat_max        float32\n",
      " 3   lon_min        float32\n",
      " 4   lon_max        float32\n",
      " 5   rain (mm/day)  float32\n",
      " 6   model          object \n",
      "dtypes: float32(5), object(2)\n",
      "memory usage: 2.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df_float32.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> | Team Member  | Operating System | RAM  | Processor         | Is SSD | Time taken    | Memory usage |\n",
    "> |:------------:|:----------------:|:----:|:-----------------:|:------:|:-------------:|:------------:|\n",
    "> | Chen, Ziyi   |                  |      |                   |        |               |              |\n",
    "> | Guron, Mike  |                  |      |                   |        |               |              |\n",
    "> | Raina, Roan  |                  |      |                   |        |               |              |\n",
    "> | Wong, Kelvin | Linux Mint 21    | 16GB | AMD Ryzen 5 3500U | YES    | 2 min 28 secs | 2.1+ GB      |\n",
    "> \n",
    "> Table 3: Time taken to read the combined CSV (approach 1: use `float32` instead of `float64`)\n",
    "\n",
    "#### Observations from Approach 1\n",
    "\n",
    "(WIP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Load only column(s) we want\n",
    "\n",
    "The dataset contains a number of columns that we may not need to use in one go. In this approach, we try to just load one column from the combined CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 s, sys: 13 s, total: 1min 5s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_only_rain = pd.read_csv(f\"{output_directory}/combined_data.csv\", usecols=[\"rain (mm/day)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62467843 entries, 0 to 62467842\n",
      "Data columns (total 1 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   rain (mm/day)  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 476.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_only_rain.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> | Team Member  | Operating System | RAM  | Processor         | Is SSD | Time taken    | Memory usage |\n",
    "> |:------------:|:----------------:|:----:|:-----------------:|:------:|:-------------:|:------------:|\n",
    "> | Chen, Ziyi   |                  |      |                   |        |               |              |\n",
    "> | Guron, Mike  |                  |      |                   |        |               |              |\n",
    "> | Raina, Roan  |                  |      |                   |        |               |              |\n",
    "> | Wong, Kelvin | Linux Mint 21    | 16GB | AMD Ryzen 5 3500U | YES    | 1 min 6 secs  | 476.6 MB     |\n",
    "> \n",
    "> Table 4: Time taken to read the combined CSV (approach 2: just load `rain (mm/day)`)\n",
    "\n",
    "#### Observations from Approach 2\n",
    "\n",
    "(WIP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA in R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we explore the EDA in R instead of Python. We try \"exporting\" our data frame as a Parquet file for processing in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.3 s, sys: 8.75 s, total: 39.1 s\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.to_parquet(f\"{output_directory}/combined_data.parquet\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Why we choose Parquet?\n",
    "> \n",
    "> (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘arrow’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:utils’:\n",
      "\n",
      "    timestamp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(dplyr)\n",
    "library(arrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "r_parquet <- open_dataset(\"../data/combined_data.parquet\")\n",
    "r_df <- r_parquet |> collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tibble [62,467,843 × 7] (S3: tbl_df/tbl/data.frame)\n",
      " $ time         : chr [1:62467843] \"1889-01-01 12:00:00\" \"1889-01-02 12:00:00\" \"1889-01-03 12:00:00\" \"1889-01-04 12:00:00\" ...\n",
      " $ lat_min      : num [1:62467843] -35.8 -35.8 -35.8 -35.8 -35.8 ...\n",
      " $ lat_max      : num [1:62467843] -34.9 -34.9 -34.9 -34.9 -34.9 ...\n",
      " $ lon_min      : num [1:62467843] 141 141 141 141 141 ...\n",
      " $ lon_max      : num [1:62467843] 142 142 142 142 142 ...\n",
      " $ rain (mm/day): num [1:62467843] 5.13e-01 9.23e-04 9.39e-06 2.52e-05 1.33e-05 ...\n",
      " $ model        : chr [1:62467843] \"NorESM2-MM_daily_rainfall_NSW\" \"NorESM2-MM_daily_rainfall_NSW\" \"NorESM2-MM_daily_rainfall_NSW\" \"NorESM2-MM_daily_rainfall_NSW\" ...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "r_df |> str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%R\n",
    "r_df |> summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "r_df |> head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%R\n",
    "r_df |> tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsci525",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
